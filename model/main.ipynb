{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d7f0ac-620d-4836-802b-2bb20ff58ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5afcdfda-2350-4381-99fa-2a3c90b7a719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "38339c87-d9c1-4d72-affb-aa1530b459c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of unfiltered business data: 150346 lines\n",
      "Length of filtered business data: 61919 lines\n",
      "Number of business id in business data: 61919 lines\n",
      "Length of filtered path data: 60448 lines\n",
      "Processed /Users/davidcastrejon/Documents/CSC180/hw/yelp/yelp_dataset/yelp_academic_dataset_checkin.json\n",
      "Length of filtered path data: 799452 lines\n",
      "Processed /Users/davidcastrejon/Documents/CSC180/hw/yelp/yelp_dataset/yelp_academic_dataset_tip.json\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the path to the JSON file\n",
    "business_path = '/Users/davidcastrejon/Documents/CSC180/hw/yelp/yelp_dataset/yelp_academic_dataset_business.json'\n",
    "checkin_path = '/Users/davidcastrejon/Documents/CSC180/hw/yelp/yelp_dataset/yelp_academic_dataset_checkin.json'\n",
    "review_path = '/Users/davidcastrejon/Documents/CSC180/hw/yelp/yelp_dataset/yelp_academic_dataset_review.json'\n",
    "tip_path = '/Users/davidcastrejon/Documents/CSC180/hw/yelp/yelp_dataset/yelp_academic_dataset_tip.json'\n",
    "user_path = '/Users/davidcastrejon/Documents/CSC180/hw/yelp/yelp_dataset/yelp_academic_dataset_user.json'\n",
    "\n",
    "paths = [review_path, checkin_path, tip_path]\n",
    "\n",
    "# Open the business file and read it line by line\n",
    "data = []\n",
    "with open(business_path, 'r') as f:\n",
    "    for line in f:\n",
    "        # Parse each JSON object and append it to the data list\n",
    "        entry = json.loads(line)\n",
    "        data.append(entry)\n",
    "print(f'Length of unfiltered business data: {len(data)} lines')\n",
    "\n",
    "# Define a function to filter entries with less than 20 total reviews\n",
    "def filter_reviews(entry):\n",
    "    return entry['review_count'] >= 20\n",
    "\n",
    "# Filter the entries for businesses with more than 20 reviews\n",
    "filtered_data = list(filter(filter_reviews, data))\n",
    "\n",
    "# Specify the path for the new JSON file\n",
    "output_file = 'filtered_yelp_academic_dataset_business.json'\n",
    "\n",
    "# Save the filtered business dataset to a JSON file\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(filtered_data, f, indent=4)\n",
    "\n",
    "# Read the entire file and parse it as a JSON array\n",
    "with open(output_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Now, the data list contains all the parsed JSON objects from the file\n",
    "print(f'Length of filtered business data: {len(data)} lines')\n",
    "\n",
    "# Extract business IDs from the filtered data\n",
    "filtered_business_ids = [entry['business_id'] for entry in data]\n",
    "print(f'Number of business id in business data: {len(data)} lines')\n",
    "\n",
    "# Define a function to filter entries based on business IDs\n",
    "def filter_entries(entry):\n",
    "    return entry['business_id'] in filtered_business_ids\n",
    "\n",
    "# Iterate through each path\n",
    "for path in paths:\n",
    "    # Define the output file name for the filtered data\n",
    "    output_file = f'filtered_{os.path.basename(path)[:-5]}.json'\n",
    "\n",
    "    # Open the file and read it line by line\n",
    "    filtered_data = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            # Parse each JSON object and filter entries based on business IDs\n",
    "            entry = json.loads(line)\n",
    "            if filter_entries(entry):\n",
    "                filtered_data.append(entry)\n",
    "\n",
    "    # Save the filtered dataset to a JSON file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(filtered_data, f, indent=4)\n",
    "    print(f'Length of filtered path data: {len(filtered_data)} lines')\n",
    "    print(f'Processed {path}')\n",
    "print('Finished!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a05804e8-0876-419a-9463-c5116ba7b453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Extracting text reviews and star ratings...\n",
      "6114269\n",
      "6114269\n",
      "Performing TF-IDF Vectorization...\n",
      "Finished!\n",
      "Performing Train-Test Split...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the path to the JSON file\n",
    "filtered_business_path = '/Users/davidcastrejon/Documents/CSC180/hw/yelp/filtered_yelp_academic_dataset_business.json'\n",
    "filtered_checkin_path = '/Users/davidcastrejon/Documents/CSC180/hw/yelp/filtered_yelp_academic_dataset_checkin.json'\n",
    "filtered_review_path = '/Users/davidcastrejon/Documents/CSC180/hw/yelp/filtered_yelp_academic_dataset_review.json'\n",
    "filtered_tip_path = '/Users/davidcastrejon/Documents/CSC180/hw/yelp/filtered_yelp_academic_dataset_tip.json'\n",
    "filtered_user_path = '/Users/davidcastrejon/Documents/CSC180/hw/yelp/filtered_yelp_academic_dataset_user.json'\n",
    "\n",
    "# Load data from the reviews JSON file\n",
    "print(\"Loading data...\")\n",
    "with open(filtered_review_path, 'r') as f:\n",
    "    reviews_data = json.load(f)\n",
    "    \n",
    "# Extract text reviews and star ratings\n",
    "print(\"Extracting text reviews and star ratings...\")\n",
    "texts = [review['text'] for review in reviews_data]\n",
    "stars = [review['stars'] for review in reviews_data]\n",
    "\n",
    "print(len(texts))\n",
    "print(len(stars))\n",
    "\n",
    "# TF-IDF Vectorization with min_df and max_df\n",
    "print(\"Performing TF-IDF Vectorization...\")\n",
    "vectorizer = TfidfVectorizer(min_df=.4, max_df=0.6)  # Adjust min_df and max_df values as needed\n",
    "X = vectorizer.fit_transform(texts)\n",
    "X = X.toarray()\n",
    "print(\"Finished!\")\n",
    "\n",
    "# Train-test split\n",
    "print(\"Performing Train-Test Split...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, stars, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "236164dd-e0f7-4624-b16e-376a124981e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (4891415, 11)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of X_train:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Check the shape of y_train\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of y_train:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Check the shape of X_test\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of X_test:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_test\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check the shape of X_train\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "\n",
    "# Check the shape of y_train\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "\n",
    "# Check the shape of X_test\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "\n",
    "# Check the shape of y_test\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23433b50-8b76-41e8-b66b-d90a94f34ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized data type: x=[[0.         0.         0.         ... 0.60526911 0.         0.        ]\n [0.23194477 0.         0.41139921 ... 0.24214848 0.4483258  0.23116176]\n [0.         0.         0.         ... 0.         0.         0.        ]\n ...\n [0.         0.         0.         ... 0.         0.         0.74903734]\n [0.55521324 0.47752286 0.         ... 0.         0.         0.        ]\n [0.         0.         0.         ... 0.         0.         0.        ]] (of type <class 'numpy.ndarray'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m monitor \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m checkpointer \u001b[38;5;241m=\u001b[39m ModelCheckpoint(filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdnn/best_weights.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# save best model\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdnn/best_weights.keras\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# load weights from best model\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/CSC180/HW/yelp/yelp_venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/CSC180/HW/yelp/yelp_venv/lib/python3.10/site-packages/keras/src/trainers/data_adapters/__init__.py:113\u001b[0m, in \u001b[0;36mget_data_adapter\u001b[0;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GeneratorDataAdapter(x)\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# TODO: should we warn or not?\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# warnings.warn(\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m#     \"`shuffle=True` was passed, but will be ignored since the \"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized data type: x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized data type: x=[[0.         0.         0.         ... 0.60526911 0.         0.        ]\n [0.23194477 0.         0.41139921 ... 0.24214848 0.4483258  0.23116176]\n [0.         0.         0.         ... 0.         0.         0.        ]\n ...\n [0.         0.         0.         ... 0.         0.         0.74903734]\n [0.55521324 0.47752286 0.         ... 0.         0.         0.        ]\n [0.         0.         0.         ... 0.         0.         0.        ]] (of type <class 'numpy.ndarray'>)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from sklearn import metrics\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Build the model\n",
    "print(\"Building the model...\")\n",
    "model = Sequential()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Output layer with a single neuron (for regression)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=\"dnn/best_weights.keras\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "model.fit(X_train, y_train ,callbacks=[monitor,checkpointer],verbose=2,epochs=1000)\n",
    "\n",
    "model.load_weights('dnn/best_weights.keras') # load weights from best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35455fee-dc6a-43b6-ae4d-abf76555086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Define model checkpoint callback to save the best weights\n",
    "checkpoint_path = \"best.weights.h5\"\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True, save_weights_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# Build the model\n",
    "print(\"Building the model...\")\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Output layer with a single neuron (for regression)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# Load the best weights\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Evaluating the model...\")\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Prediction\n",
    "print(\"Performing prediction on a new review...\")\n",
    "new_review = [\"This gym is amazing! The instructors are knowledgeable and motivating.\"]\n",
    "X_new = vectorizer.transform(new_review).toarray()\n",
    "predicted_star_rating = model.predict(X_new)\n",
    "print(\"Predicted Star Rating:\", predicted_star_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8489528a-d3c8-4b72-836a-330e2b1ed642",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87079806-3d6b-44da-9bb2-b35ee356e984",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m      2\u001b[0m pred\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Calculate regression metrics\n",
    "mae = mean_absolute_error(y_true, pred)\n",
    "mse = mean_squared_error(y_true, pred)\n",
    "rmse = mean_squared_error(y_true, pred, squared=False)  # Compute RMSE from MSE\n",
    "r2 = r2_score(y_true, pred)\n",
    "\n",
    "# Print regression report\n",
    "print(\"Regression Report:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c541dbb8-32f6-4e73-ac42-6c18612cc014",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true= np.argmax(y_test,axis=1) \n",
    "\n",
    "score = metrics.accuracy_score(y_true, pred)\n",
    "\n",
    "print(\"Accuracy score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c547c7-276c-4f2d-8040-d92bebeabbae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241m.\u001b[39mprecision_score(y_true, pred, average\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision score: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(score))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "score = metrics.precision_score(y_true, pred, average= \"weighted\")\n",
    "print(\"Precision score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f9fdfbc-d107-4522-9452-0354622f76f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241m.\u001b[39mrecall_score(y_true, pred, average\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall score: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(score))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "score = metrics.recall_score(y_true, pred, average= \"weighted\")\n",
    "print(\"Recall score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd4407a-9d2c-4aae-bf22-cdbc25b47849",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241m.\u001b[39mf1_score(y_true, pred, average\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 score: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(score))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "score = metrics.f1_score(y_true, pred, average= \"weighted\")\n",
    "print(\"F1 score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c9690-526e-4362-8b0e-795a704ae575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
